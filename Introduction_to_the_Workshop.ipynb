{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is statistics?\n",
    "The tasks that unifies all research are;\n",
    "\n",
    "- to decide on the type and structure of data to collect in order to best prove (or disprove) your hypotheses\n",
    "- to infer conclusions from the data that has been collected\n",
    "- to present your data and its support for your conclusions\n",
    "\n",
    ">**Statistics** is the branch of mathematics invented to deal with data and tackle sampling, inference and presentation in a logical way.\n",
    "\n",
    "The workshop only discusses a sample selection of ideas behind the inference arm of statistics. \n",
    "\n",
    "To discuss the vices and virtues of bayesian and frequentist methodologies\n",
    "To teach the fundamentals of constructing bayesian models and the algorithms that solve them\n",
    "To introduce the Stan probabilistic programming language, specifically its Python interface\n",
    "\n",
    "# Bayesian vs Frequentist\n",
    "\n",
    "Inevitably, we will never be able to collect the ideal data set. Pragmatism will always be the order of the day. The underlying usefulness of statistical inference is the ability to quantify the uncertainty of our decisions and conclusions given our imperfect data set. The task of quantifying what you do not know is an understandably non-trivial task. There are therefore two main schools of thought on how to solve this problem.\n",
    "\n",
    "Frequentist statistics, otherwise known as classical statistics, is based on the assumption that an ideal distribution actually exists for any given data problem. If we were able to sample an infinite number of data sets in identical conditions we would reveal this 'population' distribution exactly. Any variation between data sets is simply due to the finite nature of our sampling. In the frequentist framework “the parameters are fixed and the data is random”.\n",
    "\n",
    "Bayesian statistics refuses the assumptions of the frequentist statistics, that if all information was known (i.e. infinite sampling) an absolute population distribution would be found. Bayesian methods are very pragmatic in their approach by collating all the information known prior to the experiment and supplementing it with any extra information gained from the new data collected to determine whether the hypotheses are now more or less likely than before. In the Bayesian framework “the data is fixed but the parameters are random”\n",
    "\n",
    "Textbook statistics problem: \n",
    "\n",
    "You have a die and are testing whether or not it is bias. You roll it ten times and get 4 sixes, is it a normal die?\n",
    "\n",
    "*Frequentist Approach*: \n",
    "\n",
    "The null hypothesis for the probability of getting X numbers of sixes is a binomial with parameter p fixed at 1/6. Given this null distribution, what is the probability you get a data sample with 4 sixes and values around it?\n",
    "\n",
    "*Bayesian Approach*:\n",
    "\n",
    "You have a sample of 10 rolls with 4 sixes, plus a general a-priori estimate for the binomial parameter, something around 1/6. Given this data, what is the probability of p being 1/6 and values around it?\n",
    "\n",
    "# So, what is the REAL difference\n",
    "\n",
    "In frequentist methods we have a null hypothesis for the global distribution and are asking question about whether the sample we have is a good representation of the global distribution. \n",
    "\n",
    "# Why don't we already use Bayesian Statistics?\n",
    "\n",
    "1) **Intimidation**\n",
    "\n",
    "The endless pursuit of abstraction and increasing generality makes mathematics very difficult to digest. The Bayesian method has a solid logical base in probability theory, unlike frequentist methods. This is great! However, it means Bayesian textbooks tend to get bogged down with the mathematical justification before hitting the applications. This can be very difficult for practitioners, often non-mathematicians, to overcome. \n",
    "\n",
    "2) **Computation**\n",
    "\n",
    "The Bayesian quest for a distribution across all of the parameter space, rather than point statistics to summarise the space, means lots of calculations need to be done. Historically this limited the application of Bayesian method to cases where the model was analytical solvable. Therefore reducing the possible choices of models to very few practical cases. The development of fast and cheap computer processors have change that. (Now the lack of coding skills gets in the way)\n",
    "\n",
    "3) **Subjectivity**\n",
    "\n",
    "There is a strong critique of Bayesian inference based on the effects of ‘prior’ distributions inside the model. Since you define these before you input any data into your model some people find the effects of non-data orientated information uneasy. They choose to wrangle with the numerous caveats of frequentist methods.\n",
    "\n",
    "# Why swap to Bayesian?\n",
    "\n",
    "There is nothing implicitly wrong with using frequentist methods! They are generally faster, well documented and 9 times out of 10 give the same answer as a Bayesian method. There are cases where only a bayesian method would do, i.e. trying to fit ~10000 parameter model to your data using maximum likelihood would be hell. Bayesian method are also easily modularised, so different sources of error/randomness can be incorporated together. However, the biggest pitfall of frequentist statistics is the detection of those 1 in 10 times the method gets it wrong. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
