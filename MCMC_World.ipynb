{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All of Python in Three minutes\n",
    "\n",
    "### Basic variables\n",
    "Progamming languages group data into many many \"variable types\", i.e. character, float, integer, boolean. Why? \n",
    "\n",
    "- Memory allocation\n",
    "\n",
    "A float (or number with a decimal place) requires significantly more memory than an integer\n",
    "- Alternative function calls\n",
    "\n",
    "3 + 5 = 8 if both 3 and 5 are defined as integers but \"3\" + \"5\" = \"35\" if 3 and 5 are defined as strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "3 + 5\n",
    "\"3\" + \"5\"\n",
    "3 + \"5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Debugging\n",
    "\n",
    "Having strict variable types allows you to quickly find bugs due to the wrong data being passed into your code!\n",
    "\n",
    "Python is a \"dynamically typed\" progamming language, you do not have to declare what type a variable will be before giving a value. Instead, once you assign a variable a value Python will guess the variable type. This distinction\n",
    "will become clearer when we talk about Stan which is a \"statically typed\" language based on C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = 3\n",
    "type1 = type(variable)\n",
    "variable = 3.142\n",
    "type2 = type(variable)\n",
    "variable = \"3.142\"\n",
    "type3 = type(variable)\n",
    "\n",
    "print (\"3\" + \" \" + str(type1) + \"\\n\" + \"3.142\" + \" \" + \n",
    "       str(type2) + \"\\n\" + \"\\\"3.142\\\" \" + str(type3) + \"\\n\" + \"type1 \" + str(type(type1)))\n",
    "# Notice that I had to recast the type1 variable as a string in order to be able to use \n",
    "# the + operator to produce the printed string \n",
    "# This is because the + operator can only combine (concantenate) strings and the type1 variable\n",
    "# is a 'type' variable type\n",
    "# You can now see how complex variable types can be and therfore\n",
    "# the benefits of having a progamming language that deals with some of it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Variables\n",
    "\n",
    "There are an endless list of variable types for all sorts of uses, for now I will only cover lists and dictionaries as they are crutial for using Stan.\n",
    "\n",
    "Lists are the most common way to group variables, the elements of a list do not need to be of the same type! To declare a variable as a list we use [ ] brackets. You can select elements in a list with [ ] too!\n",
    "\n",
    "Dictionaries are a type of variable native to python that deal with relational data, i.e. data that you want to group together because they are somewhat related. You define a variable as a dictionary by using curly brackets { }, keys are separated by commas and values with colons : . The you can select keys from the dictionary with square bracket [ ] to see their values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Dictionary of lists\n",
    "variable = {\n",
    "    \"Africa\" : [\"Nigeria\", \"Ethiopia\", \"Algeria\", \"Côte d’Ivoire\"],\n",
    "    \"Asia\" : [\"China\", \"India\", \"Vietnam\", \"Brunei\"],\n",
    "    \"Europe\" : [\"France\", \"UK\", \"Estonia\", \"Sweden\"],\n",
    "    \"North America\" : [\"USA\",\"Canada\"],\n",
    "    \"South America\" : [\"Chile\", \"Uruguay\",\"Brazil\"]\n",
    "}\n",
    "\n",
    "variable\n",
    "type(variable)\n",
    "\n",
    "variable[\"Africa\"]\n",
    "type(variable[\"Africa\"])\n",
    "\n",
    "variable[\"Africa\"][0] # Lists in python start at element 0!\n",
    "type(variable[\"Africa\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries\n",
    "\n",
    "Libraries are collections of functions and objects usually with a unifying aim, such as machine learning, graph plotting or mathematical simulation. Obviously loading up every possible function for every coding script simply for the slight chance it might be called would lead to a huge computational overhead (and a nightmarish naming scheme). Therefore libraries allow you to limit and organise which functions are available at any one time. The majority of libraries you will use are created and maintained by professional programmers (such as pystan), although if you get good enough at coding you can create you own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The standard way of using a library is to load all of the functions (and objects) associated with it\n",
    "import matplotlib.pyplot\n",
    "\n",
    "# In cases where you are using a variety of functions from different libraries it may be best to specify what you\n",
    "# want to use rather then the whole library. This can help with avoiding clashing function names\n",
    "from numpy.random import normal\n",
    "\n",
    "# If the library has a long name you may want to shorten it \n",
    "#(be careful not to override another function!)\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"x\" : normal(6, 4, 10000), \"y\" : normal(4, 6, 10000)})\n",
    "matplotlib.pyplot.plot(df[\"x\"],df[\"y\"],'r.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and manipulating data\n",
    "\n",
    "All the data used in this workshop are ideally formated .csv files. If only life was always so kind. And no, I am not going into how to deal with nightmarish file formats biologists love to create. Enjoy it while it lasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importedCsvFile = pd.read_csv(\"./data/evaluation_discoveries.csv\")\n",
    "\n",
    "importedCsvFile\n",
    "                              \n",
    "# Dataframes are like dictionaries, you need to name the column before you specify an element                           \n",
    "importedCsvFile[\"time\"][1]\n",
    "\n",
    "# You specify groups of elements if you want. Remember the first element is actually the 0th!\n",
    "importedCsvFile[\"time\"][0:10]\n",
    "\n",
    "# To select a strange range of elements you can use for loops and if functions\n",
    "for i in range(0,10) :\n",
    "        if( (i % 2) == 0) : importedCsvFile[\"time\"][i] # choose first 5 even years only\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting graphs\n",
    "Above we have used matplotlib to draw graphs which will be familiar to any matlab users. However, for ease we will use the seaborn library, a high level version of matplotlib, as it already has the functions we need to plot the graphs we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "\n",
    "plotData = pd.DataFrame({\"Random1\" : normal(30, 15, 100), \"Random2\" : normal(6, 3, 100)})\n",
    "\n",
    "# Passing a pandas dataframe to seaborn allows you select which parameters to plot on which axis\n",
    "sns.relplot(\"Random1\", \"Random2\", data=plotData)\n",
    "\n",
    "# You can plot even more complex graphs relatively easily\n",
    "sns.jointplot(\"Random1\", \"Random2\", data=plotData, kind=\"reg\",\n",
    "                  xlim=(-20, 80), ylim=(-6, 18), color=\"m\", height=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick test\n",
    "Using this [list](https://docs.scipy.org/doc/numpy-1.15.1/reference/routines.random.html) of random variable distributions available in numpy, plot a kernel density estimate plot of two lots of 1000 samples from a gamma distribution with shape parameter of 2 and scale parameter of 3. See [this](https://seaborn.pydata.org/tutorial/distributions.html) website to learn the code to plot a kernel density estimate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create the numpy dataframe with the two lots of gamma distributed random vectors\n",
    "\n",
    "# Output the first 7 odd elements for each vector\n",
    "\n",
    "# Then plot the kernel density estimate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Its a MCMC life \n",
    "\n",
    "\n",
    "With some Python Basics covered, we'll now discuss the need for computing in Bayesian analysis. It essentially boils down to the definition of the evidence in Bayes theorem $P(x)=\\int f(\\theta,x)P(\\theta)d\\theta$. Very quickly this equation becomes intractable (unless you choose your priors carefully and not necessarily pratically) or at least very difficult to solve;\n",
    "\n",
    "$$\\text{Likelihood} = f(\\theta,x) \\sim poisson(\\theta)$$\n",
    "\n",
    "$$\\text{Prior} = P(\\theta) \\sim lognormal(1,1)$$\n",
    "\n",
    "$$\\text{Evidence} = P(x) = \\int^\\infty_0\\Bigg(\\prod^N_{i=1}\\frac{\\lambda^{x_i}exp(-\\lambda)}{x_i!}\\Bigg)\\times\\frac{1}{\\lambda\\sqrt{2\\pi}}exp\\Bigg(-\\frac{(log(\\lambda)-1)^2}{2}\\Bigg)d\\lambda.$$\n",
    "\n",
    "The above equation may look complex but represents a relatively simple model. The likelihood consists of only one parameter, the poisson rate.  Typically you want to find the distribution of several (and often hundreds if not thousands) of parameters. You can try to use numerical integrators but they will struggle to converge when you get beyond ~10 independent parameters.\n",
    "\n",
    "MCMC methods are a type of algorithm that help estimate complex distributions. MCMC stands for Markov Chain Monte Carlo. Monte Carlo, a reference to the famous casino in Monaco, is an umbrella term for pretty much any algorithm that requires random sampling from a distribution (very common in simulations). Markov Chain refers to a specific type of random process where the outcome of the previous step effects the probabilities of the next step. It is important to emphasis that ONLY the last step matters, not the entire history. This allows some retention of information so the sampling can be somewhat guided, i.e. to a maximum or minimum. \n",
    "\n",
    "If we get values of (3.26,4.45,2.98,4.98,3.50) from a gamma distribution, lets go through an basic algorithm for an MCMC method to estimate the parameters for $\\alpha$ and $\\beta$.\n",
    "\n",
    "**Likelihood**\n",
    "$$P(3.26,4.45,2.98,4.98,3.50) = \\sum_i\\frac{\\beta^\\alpha}{\\Gamma(\\alpha)}i^{\\alpha -1}e^{-i\\beta} $$\n",
    "where $i \\in [3.26,4.45,2.98,4.98,3.50]$\n",
    "\n",
    "**Priors**\n",
    "$$\\alpha \\sim Gamma(1,1), \\beta \\sim Gamma(1,1)$$\n",
    "\n",
    "**Algorithm**\n",
    "\n",
    "1) Randomly sample values for both parameters $\\alpha$ and $\\beta$\n",
    "\n",
    "2) Use prior distribution to work out the probability of getting these parameter\n",
    "\n",
    "3) Calculate the probability of getting this sample with these values using the likelihood\n",
    "\n",
    "4) Multiply the prior probability and likelihood and store as $p_{current}$\n",
    "\n",
    "5) Randomly sample a value for $\\alpha$, keeping $\\beta$ fixed\n",
    "\n",
    "6) Repeat steps 2-4 to create the variable $p_{new}$\n",
    "\n",
    "7) Change $\\alpha$ to new value with probability ${p_{new}}/{p_{current}}$\n",
    "\n",
    "8) Repeat steps 5-7 keeping $\\alpha$ constant but changing $\\beta$\n",
    "\n",
    "9) Iterate changing $\\alpha$ and $\\beta$ until convergance!\n",
    "\n",
    "\n",
    "The first, rather open ended question, is how many repeats/iterations of this code do we need to do before we get to a reasonable approximation of the posterior? Considering we start from an entirely random position ( and each starting point is not created equally) the larger the number of iterations you do the better! Of the order of 1000 for smaller models is fine. Speaking about unequal starting points and checking if we've converged on the actual posterior, most MCMC's repeat the sampling process multiple times in parallel, then compare to see if they give similar values. Each separate sampling process is called a chain, normally about 4 are done in parallel.\n",
    "\n",
    "The are many subtleties to MCMC sampling which I simply cannot cover here. Issues such as adjusting the sampling rate to converge on the posterior faster as well as checking whether the algorithm has reached a local or global maximum value. Stan's [manual](https://mc-stan.org/users/documentation/) covers the important decisions and discusses its own version of an MCMC called NUTS (no u-turn sampling) if you are interested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_current = mu_init\n",
    "posterior = [mu_current]\n",
    "for i in range(samples):\n",
    "    # suggest new position\n",
    "    mu_proposal = norm(mu_current, proposal_width).rvs()\n",
    "\n",
    "    # Compute likelihood by multiplying probabilities of each data point\n",
    "    likelihood_current = norm(mu_current, 1).pdf(data).prod()\n",
    "    likelihood_new = norm(mu_new, 1).pdf(data).prod()\n",
    "        \n",
    "    # Compute prior probability of current and proposed mu        \n",
    "    prior_current = norm(mu_prior_mu, mu_prior_sd).pdf(mu_current)\n",
    "    prior_proposal = norm(mu_prior_mu, mu_prior_sd).pdf(mu_proposal)\n",
    "        \n",
    "    p_current = likelihood_current * prior_current\n",
    "    p_new = likelihood_new * prior_new\n",
    "        \n",
    "    # Accept proposal?\n",
    "    p_accept = p_new / p_current\n",
    "\n",
    "    if accept:\n",
    "        # Update position\n",
    "        mu_current = mu_new\n",
    "        \n",
    "    posterior.append(mu_current)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The many faces of Stan\n",
    "\n",
    "Stan is a programming language in its own right, focused primarily on solving probabilistic progamming problems and is easily nestled into other more general progamming languages (i.e. Python). A script of stan code consists of at least three sections; data, parameters and model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_code=\"\"\"\n",
    "data{\n",
    "    Here you specify the details about the type (as stan is a static typed language) and shape\n",
    "    of your data. This is what stan will use to adjust your likelihood.\n",
    "}\n",
    "\n",
    "parameters{\n",
    "    Here you specify what parameters you want stan to find out, their type and how many.\n",
    "}\n",
    "\n",
    "model{\n",
    "    Then finally you need to tell stan what the priors are for the parameters and what the\n",
    "    likelihood is for you data.\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stan is a typed language\n",
    "\n",
    "As stated previously, Stan is a typed language so you need to declare a variable's type before assigning it a value (if you attempt to assign a value of a different type to the one declared, then a error message will be sent). The main variables in Stan are;\n",
    "\n",
    "    int - integer\n",
    "    \n",
    "    real - float (decimal number) \n",
    "    \n",
    "    array\n",
    "\n",
    "There are more, some of which are very important for efficient use of Stan, i.e. vectors, but we shall not cover them here. \n",
    "\n",
    "In stan you can declare \n",
    "\n",
    "    int var1 \n",
    "which will allow you to place one integer into this variable. Alternatively you can define an integer array \n",
    "\n",
    "    int var2[3]\n",
    "which would allow you to pass three integers to stan, the same can be done for real. As you can see this is very helpful when passing your data to stan for inference. In fact, you can actually wait until runtime to define the size of the int/real array; first define a normal integer \n",
    "    \n",
    "    int size\n",
    "then as long as a value for this passed before a value for the array you can define your variable as \n",
    "\n",
    "    int var3[size]\n",
    "So if you trial your code on a sub set of your data, you dont have to rewrite you stan code!\n",
    "\n",
    "### Limits are vital!\n",
    "During the delcaration of a variable type you also specify if the variable has minimum or maximum value with triangular brackets, < >: \n",
    "\n",
    "    int<lower=0,upper=1> var4\n",
    "It is exceptionally important to put any limits on the variables representing your parameters. This directly effects how stan samples random values for the parameter and so can massively decrease the run time.\n",
    "\n",
    "### Stan is based somewhat on C\n",
    "Therefore you have slightly different syntax! Comments are denoted by // not #. Each line of code must end with a semi-colon ; not a newline \\n! A semi-colon is not necessary if there already is a clear endpoint due to curly brackets {}. \n",
    "\n",
    "Finally, like C any stan code must be compiled before use (this is unlike any python/R/Matlab code you've ran before). This is a time consuming process itself but allows for the actual stan code to run much quicker! If you only change the data inputted into the model not the model code itself than you do not need to (and should't) recompile the code!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_code =\"\"\"\n",
    "data{\n",
    "    // This will be commented out\n",
    "    int<lower=1> size;\n",
    "    int var1[size];\n",
    "}\n",
    "parameter{\n",
    "    real<lower=2,upper=4> theta;\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule Number One of Stan\n",
    "\n",
    "**NEVER** interrupt it during sampling/compiling\n",
    "\n",
    "Although generally very stable, albeit with odd and unhelpful errors, it is very hard to interrupt Stan once it gets going (i.e. the best thing to do is restart you computer or get good at terminating processes from you terminal!). If you do interrupt, the process sometimes just continues in the background heating uo your laptop. Always run you code with a small subset of you data and only 1 chain and ~ 10 iterations first. This will allow you to identify any bugs that will break you stan code (and cause it to never converge...)\n",
    "\n",
    "# Example Stan code for the previous jelly baby trial!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystan\n",
    "\n",
    "model_code=\"\"\"\n",
    "data {\n",
    "  // Number of trials\n",
    "  // This is defined as an integer with a minimal value of 1\n",
    "  int<lower=1> NTRIAL;     \n",
    "  \n",
    "  // Array of integers for the outcome of each trial\n",
    "  // This is defined as an integer array with a minimal value of 0 and max of 1\n",
    "  int<lower=0, upper=1> outcome[NTRIAL];\n",
    "}\n",
    "parameters {\n",
    "  // we want to find out the parameter for the binomial\n",
    "  // it must be between 0 and 1\n",
    "  real<lower=0, upper=1> theta;\n",
    "}\n",
    "model{\n",
    "  // first define the prior \n",
    "  \n",
    "  theta ~ normal(0.25,0.1);\n",
    "  \n",
    "  // then the likelihood\n",
    "  \n",
    "  for(i in 1:NTRIAL) {\n",
    "     outcome[i] ~ bernoulli(theta);\n",
    "  }\n",
    "\n",
    "}\n",
    "\"\"\"\n",
    "# This line of code compiles the c based python model for later calling!\n",
    "bernoulliModel = pystan.StanModel(model_code=model_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we run a simulation?\n",
    "We have a compiled stan model but we need to give it some data! The easiest why to give data to stan is to define a dictionary with key names equal to the variable names defined in the data chunk and values equal in type and size to that declared in the stan code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dictionary for the data to feed the bayesian model, 0 = vegan, 1 = non-vegan\n",
    "stan_data = {'NTRIAL': 10, 'outcome': [0,0,1,0,1,1,0,0,0,1]}\n",
    "\n",
    "# <stanModelName>.sampling starts the actual MCMC\n",
    "# you need to state the variable holding the data for stan, the number iterations to complete\n",
    "# and finally the number of chains you want to initialise in parallel\n",
    "\n",
    "# first do a trial run\n",
    "bernoulliStanFit = bernoulliModel.sampling(data = stan_data,iter = 2000, chains = 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And then the real thing and estimate the actual posterior\n",
    "bernoulliStanFit = bernoulliModel.sampling(data = stan_data,iter = 2000, chains = 4)\n",
    "\n",
    "# Once this is finished you can uncouple the parameters sampled from the posterior\n",
    "parameters = bernoulliStanFit.extract()\n",
    "\n",
    "# And then plot\n",
    "\n",
    "# Import libraries for easy graph creation (seaborn) and useful array manipulation / numerical functions (numpy)\n",
    "import numpy as np\n",
    "\n",
    "# Output the values for theta sampled from the posterior as a smoothed density plot\n",
    "sns.set_style('whitegrid') # Formats seaborn plot in easily readable style\n",
    "\n",
    "# Plot seaborn density graph with smoothed values (as we are actually plotting many discrete values)\n",
    "sns.kdeplot(np.array(parameters[\"theta\"]), bw=0.02) # bw stands for bandwidth and adjust smoothing rate"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
